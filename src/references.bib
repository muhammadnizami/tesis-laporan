@book{knuth2001art,
    title={The Art of Computer Programming: Fundamental Algorithms},
    author={Knuth, D.E.},
    number={v. 1},
    isbn={9780201896831},
    series={The Art of Computer Programming: Fundamental Algorithms},
    year={2001},
    publisher={Addison-Wesley}
}
@INPROCEEDINGS{4026885,
    author={W. Vogels},
    booktitle={2006 IEEE International Conference on Services Computing (SCC'06)},
    title={Web Services at Amazon.com},
    year={2006},
    pages={xxii-xxii},
    keywords={Distributed computing;Technological innovation;Web services},
    doi={10.1109/SCC.2006.116},
    month={Sept}
}
@article{schubert2017test,
author = {Emery Schubert and Sergio Canazza and Giovanni De Poli and Antonio Rodà},
title = {Algorithms can Mimic Human Piano Performance: The Deep Blues of Music},
journal = {Journal of New Music Research},
volume = {46},
number = {2},
pages = {175-186},
year  = {2017},
publisher = {Routledge},
doi = {10.1080/09298215.2016.1264976},

URL = { 
        https://doi.org/10.1080/09298215.2016.1264976
    
},
eprint = { 
        https://doi.org/10.1080/09298215.2016.1264976
    
}

}



@article{marchini2014quartet,
author = {Marco Marchini and Rafael Ramirez and Panos Papiotis and Esteban Maestre},
title = {The Sense of Ensemble: a Machine Learning Approach to Expressive Performance Modelling in String Quartets},
journal = {Journal of New Music Research},
volume = {43},
number = {3},
pages = {303-317},
year  = {2014},
publisher = {Routledge},
doi = {10.1080/09298215.2014.922999},

URL = { 
        https://doi.org/10.1080/09298215.2014.922999
    
},
eprint = { 
        https://doi.org/10.1080/09298215.2014.922999
    
}

}

@inproceedings{yu2017bowing,
  author    = {Lauren Jane Yu and
               Andrea Pohoreckyj Danyluk},
  title     = {Predicting Expressive Bow Controls for Violin and Viola},
  booktitle = {Computational Intelligence in Music, Sound, Art and Design - 6th International
               Conference, EvoMUSART 2017, Amsterdam, The Netherlands, April 19-21,
               2017, Proceedings},
  pages     = {354--370},
  year      = {2017},
  url       = {https://doi.org/10.1007/978-3-319-55750-2_24},
  doi       = {10.1007/978-3-319-55750-2_24},
  timestamp = {Sun, 21 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/evoW/YuD17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{lindemann2007rpm,
  title={Music Synthesis with Reconstructive Phrase Modeling},
  author={Erich Lindemann},
  journal={IEEE Signal Processing Magazine},
  year={2007},
  volume={24},
  pages={80-91}
}
@inproceedings{nsynth2017,
title = {Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders},
author  = {Jesse Engel and Cinjon Resnick and Adam Roberts and Sander Dieleman and Douglas Eck and Karen Simonyan and Mohammad Norouzi},
year  = {2017},
URL = {https://arxiv.org/abs/1704.01279}
}
@inproceedings{perez2015,
 author = {Perez, Alfonso and Ramirez, Rafael},
 title = {Towards Realistic and Natural Synthesis of Musical Performances: Performer, Instrument and Sound Modeling},
  booktitle = {the Third Vienna Talk on Music Acoustics, 16–19 Sept. 2015, University of Music and Performing Arts Vienna, Proceedings},
  pages     = {289--294},
  year      = {2015},
} 

@inproceedings{yang2016synthesis,
title = "Automatic violin synthesis using expressive musical term features",
abstract = "The control of interpretational properties such as duration, vibrato, and dynamics is important in music performance. Musicians continuously manipulate such properties to achieve different expressive intentions. This paper presents a synthesis system that automatically converts a mechanical, deadpan interpretation to distinct expressions by controlling these expressive factors. Extending from a prior work on expressive musical term analysis, we derive a subset of essential features as the control parameters, such as the relative time position of the energy peak in a note and the mean temporal length of the notes. An algorithm is proposed to manipulate the energy contour (i.e. for dynamics) of a note. The intended expressions of the synthesized sounds are evaluated in terms of the ability of the machine model developed in the prior work. Ten musical expressions such as Risoluto and Maestoso are considered, and the evaluation is done using held-out music pieces. Our evaluations show that it is easier for the machine to recognize the expressions of the synthetic version, comparing to those of the real recordings of an amateur student. While a listening test is under construction as a next step for further performance validation, this work represents to our best knowledge a first attempt to build and quantitatively evaluate a system for EMT analysis/synthesis.",
author = "Yang, {Chih Hong} and Li, {Pei Ching} and Su, {Alvin W.Y.} and Li Su and Yang, {Yi Hsuan}",
year = "2016",
language = "English",
pages = "209--215",
booktitle = "DAFx 2016 - Proceedings of the 19th International Conference on Digital Audio Effects",
publisher = "Brno University of Technology",
address = "Czech Republic",
}

@article{bonada2017singing,
  author    = {Merlijn Blaauw and
               Jordi Bonada},
  title     = {A Neural Parametric Singing Synthesizer},
  journal   = {CoRR},
  volume    = {abs/1704.03809},
  year      = {2017},
  url       = {http://arxiv.org/abs/1704.03809},
  archivePrefix = {arXiv},
  eprint    = {1704.03809},
  timestamp = {Wed, 07 Jun 2017 14:40:55 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BlaauwB17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Kirke:2009:SCS:1592451.1592454,
 author = {Kirke, Alexis and Miranda, Eduardo Reck},
 title = {A Survey of Computer Systems for Expressive Music Performance},
 journal = {ACM Comput. Surv.},
 issue_date = {December 2009},
 volume = {42},
 number = {1},
 month = dec,
 year = {2009},
 issn = {0360-0300},
 pages = {3:1--3:41},
 articleno = {3},
 numpages = {41},
 url = {http://doi.acm.org/10.1145/1592451.1592454},
 doi = {10.1145/1592451.1592454},
 acmid = {1592454},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Music performance, computer music, generative performance, machine learning},
} 
@ARTICLE{miranda2010, 
author={E. R. Miranda and A. Kirke and Q. Zhang}, 
journal={Computer Music Journal}, 
title={Artificial Evolution of Expressive Performance of Music: An Imitative Multi-Agent Systems Approach}, 
year={2010}, 
volume={34}, 
number={1}, 
pages={80-96}, 
keywords={}, 
doi={10.1162/comj.2010.34.1.80}, 
ISSN={0148-9267}, 
month={March},}
@inproceedings{Thippur2013ProbabilisticMO,
  title={Probabilistic Modeling of Bowing Gestures for Gesture-based Violin Sound Synthesis},
  author={Akshaya Thippur and Anders Askenfelt and Hedvig Kjellstr{\"o}m},
  year={2013}
}
@inproceedings{Bonada2016ExpressiveSS,
  title={Expressive Singing Synthesis Based on Unit Selection for the Singing Synthesis Challenge 2016},
  author={Jordi Bonada and Mart{\'i} Umbert and Merlijn Blaauw},
  booktitle={INTERSPEECH},
  year={2016}
}
@article{Bonada2007SynthesisOT,
  title={Synthesis of the Singing Voice by Performance Sampling and Spectral Models},
  author={Jordi Bonada and Xavier Serra},
  journal={IEEE Signal Processing Magazine},
  year={2007},
  volume={24},
  pages={67-79}
}
@inproceedings{Oord2016WaveNetAG,
  title={WaveNet: A Generative Model for Raw Audio},
  author={A{\"a}ron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew W. Senior and Koray Kavukcuoglu},
  booktitle={SSW},
  year={2016}
}

@article{Maestre2010StatisticalMO,
  title={Statistical Modeling of Bowing Control Applied to Violin Sound Synthesis},
  author={Esteban Maestre and Merlijn Blaauw and Jordi Bonada and Enric Guaus and Alfonso P{\'e}rez},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  year={2010},
  volume={18},
  pages={855-871}
}

@inproceedings{Oord2016ConditionalIG,
  title={Conditional Image Generation with PixelCNN Decoders},
  author={A{\"a}ron van den Oord and Nal Kalchbrenner and Oriol Vinyals and Lasse Espeholt and Alex Graves and Koray Kavukcuoglu},
  booktitle={NIPS},
  year={2016}
}
@article{He2016DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}
BibTeX | EndNote | ACM Ref
@article{canazza2015,
 author = {Canazza, Sergio and Poli, Giovanni De and Rod\`{a}, Antonio},
 title = {CaRo 2.0: An Interactive System for Expressive Music Rendering},
 journal = {Adv. in Hum.-Comp. Int.},
 issue_date = {January 2015},
 volume = {2015},
 month = jan,
 year = {2015},
 issn = {1687-5893},
 pages = {2:2--2:2},
 articleno = {2},
 numpages = {1},
 url = {https://doi.org/10.1155/2015/850474},
 doi = {10.1155/2015/850474},
 acmid = {2810629},
 publisher = {Hindawi Publishing Corp.},
 address = {New York, NY, United States},
} 
[download]
@unpublished{bonada2016pixelCNNsinging,
  author  = "Merlijn Blaauw and
               Jordi Bonada",
  title = "A singing synthesizer based
on PixelCNN",
  year = "2016",
  note  = "http://www.dtic.upf.edu/~mblaauw/MdM_NIPS_seminar/",
}
@article{morise2016world,
author = {Morise, Masanori and YOKOMORI, Fumiya and Ozawa, Kenji},
year = {2016},
month = {07},
pages = {1877-1884},
title = {WORLD: A Vocoder-Based High-Quality Speech Synthesis System for Real-Time Applications},
volume = {E99.D},
journal = {IEICE Transactions on Information and Systems},
doi = {10.1587/transinf.2015EDP7457}
}
@article{dudley1939vocoder,
author = {Dudley, Homer},
year = {1939},
month = {01},
pages = {},
title = {Remaking Speech},
volume = {11},
journal = {Journal of The Acoustical Society of America - J ACOUST SOC AMER},
doi = {10.1121/1.1902137}
}
@conference{morise2009fast,
    title = {Fast and Reliable F0 Estimation Method Based on the Period Extraction of Vocal Fold Vibration of Singing Voice and Speech},
    author = {Morise, Masanori and Kawahara, Hideki and Katayose, Haruhiro},
    booktitle = {Audio Engineering Society Conference: 35th International Conference: Audio for Games},
    month = {Feb},
    year = {2009},
    url = {http://www.aes.org/e-lib/browse.cfm?elib=15165}
    }
@inbook {serra1997sineplusnoise,
  title = {Musical Sound Modeling with Sinusoids plus Noise},
  booktitle = {Musical Signal Processing},
  series = {Studies on New Music Research},
  year = {1997},
  pages = {91-122},
  publisher = {Swets \& Zeitlinger},
  organization = {Swets \& Zeitlinger},
  abstract = {When generating musical sound on a digital computer, it is important to have a good model whose parameters provide a rich source of meaningful sound transformations. Three basic model types are in prevalent use today for musical sound generation instrument models, spectrum models, and abstract models. Instrument models attempt to parametrize a sound at its source, such as a violin, clarinet, or vocal tract. Spectrum models attempt to parametrize a sound at the basilar membrane of the ear, discarding whatever information the ear seems to discard in the spectrum. Abstract models, such as FM, attempt to provide musically useful parameters in an abstract formula. 
<p>
This article addresses the second category of synthesis techniques spectrum modeling. The main advantage of this group of techniques is the existence of analysis procedures that extract the synthesis parameters out of real sounds, thus being able to reproduce and modify actual sounds. Our particular approach is based on modeling sounds as stable sinusoids (partials) plus noise (residual component), therefore analyzing sounds with this model and generating new sounds from the analyzed data. The analysis procedure detects partials by studying the time-varying spectral characteristics of a sound and represents them with time-varying sinusoids. These partials are then subtracted from the original sound and the remaining \&quot;residual\&quot; is represented as a time-varying filtered white noise component. The synthesis procedure is a combination of additive synthesis for the sinusoidal part, and subtractive synthesis for the noise part.
</p>
},
  isbn = {90 265 1482 4},
  author = {Xavier Serra},
  editor = {Roads, C. and Pope, S. and Picialli, A. and De Poli, G.}
}
@ARTICLE{beauchamp1994twm,
   author = {{Maher}, R.~C. and {Beauchamp}, J.~W.},
    title = "{Fundamental frequency estimation of musical signals using a two-way mismatch procedure}",
  journal = {Acoustical Society of America Journal},
     year = 1994,
    month = apr,
   volume = 95,
    pages = {2254-2263},
      doi = {10.1121/1.408685},
   adsurl = {https://ui.adsabs.harvard.edu/abs/1994ASAJ...95.2254M},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article {sierra1990sms,
  title = {Spectral Modeling Synthesis: A Sound Analysis/Synthesis Based on a Deterministic plus Stochastic Decomposition},
  journal = {Computer Music Journal},
  volume = {14},
  year = {1990},
  note = {SMS},
  pages = {12-24},
  abstract = {When generating musical sound on a digital computer, it is important to have a good model whose parameters provide a rich source of meaningful sound transformations. Three basic model types are used widely today far musical sound generation: instrument models, spectrum models, and abstract models. Instrument models attempt to parameterize a sound at its source, such as a violin, clarinet, or vocal tract. Spectrum models attempt to parameterize a sound at the basilar membrane of the ear, discarding whatever information the ear seems to discard in the spectrum. Abstract models, such as FM, attempt to provide musically useful parameters in an abstract formula.
 This paper addresses the second category of synthesis technique: spectrum modeling. It describes a technique called spectral modeling synthesis (SMS), that models time-varying spectra as (1) a collection of sinusoids controlled through time by piecewise linear amplitude and frequency envelopes ( the deterministic part), and (2) a time-varying filtered noise component ( the stochastic part). The analysis procedure first extracts the sinusoidal trajectories by tracking peaks in a sequence of short-time Fourier transforms. These peaks are then removed by spectral subtraction. The remaining "noise floor" is then modeled as white noise through a time-varying filter. A piecewise linear approximation to the upper spectral envelope of the noise is computed for each successive spectrum, and the stochastic part is synthesized by means of the overlap-add technique. The SMS technique has proved to give general, high-quality transformations far a wide variety of musical signals.},
  doi = {http://doi.org/10.2307/3680788},
  url = {http://hdl.handle.net/10230/33796},
  author = {Xavier Serra and Smith, J.}
}

@article{morise2015cheaptrick,
title = "CheapTrick, a spectral envelope estimator for high-quality speech synthesis",
journal = "Speech Communication",
volume = "67",
pages = "1 - 7",
year = "2015",
issn = "0167-6393",
doi = "https://doi.org/10.1016/j.specom.2014.09.003",
url = "http://www.sciencedirect.com/science/article/pii/S0167639314000697",
author = "Masanori Morise",
keywords = "Speech synthesis, Speech analysis, Spectral envelope, Time-varying component",
abstract = "A spectral envelope estimation algorithm is presented to achieve high-quality speech synthesis. The concept of the algorithm is to obtain an accurate and temporally stable spectral envelope. The algorithm uses fundamental frequency (F0) and consists of F0-adaptive windowing, smoothing of the power spectrum, and spectral recovery in the quefrency domain. Objective and subjective evaluations were carried out to demonstrate the effectiveness of the proposed algorithm. Results of both evaluations indicated that the proposed algorithm can obtain a temporally stable spectral envelope and synthesize speech with higher sound quality than speech synthesized with other algorithms."
}

@phdthesis {emilia2006tonaldesc,
  title = {Tonal Description of Music Audio Signals},
  year = {2006},
  school = {Universitat Pompeu Fabra},
  abstract = {This dissertation is about tonality. More precisely, it is concerned with the problems that appear when computer programs try to automatically extract tonal descriptors from musical audio signals. This doctoral dissertation proposes and evaluates a computational approach for the automatic description of tonal aspects of music from the analysis of polyphonic audio signals. 
<p>
 In this context, we define a tonal description in different abstraction levels, differentiating between low-level signal descriptors (e.g. tuning frequency or pitch class distribution) and high-level textual labels (e.g. chords or keys). These high-level labels require a musical analysis and the use of tonality cognition models. We also establish different temporal scales for description, defining some instantaneous features as being attached to a certain time instant, and other global descriptors as related to a wider segment (e.g. a section of a song). 
</p>
<p>
 Along this PhD thesis, we have proposed a number of algorithms to directly process digital audio recordings from acoustical instruments, in order to extract tonal descriptors. These algorithms focus on the computation of pitch class distributions descriptors, the estimation of the key of a piece, the visualization of the evolution of its tonal center or the measurement of the similarity between two different musical pieces. Those algorithms have been validated and evaluated in a quantitative way. First, we have evaluated low-level descriptors, such as pitch class distribution features and estimation of the tuning frequency (with respect to 440 Hz), and their independence with respect to timbre, dynamics and other external factors to tonal characteristics. Second, we have evaluated the method for key finding, obtaining an accuracy around 80\%. This evaluation has been made for a music collection of 1400 pieces with different characteristics. We have studied the influence of different aspects such as the employed tonal model, the advantage of using a cognition-inspired model vs machine learning methods, the location of the tonality within a musical piece, and the influence of the musical genre on the definition of a tonal center. Third, we have proposed the extracted features as a tonal representation of an audio signal, useful to measure similarity between two pieces and to establish the structure of a musical play. For this, we have evaluated the use of tonal descriptors to identify versions of the same song, obtaining an improvement of 55\% over the baseline. 
</p>
<p>
 From a more general standpoint, this dissertation substantially contributes to the field of computational tonal description 
</p>
<ul>
   
  <li> It provides a multidisciplinary review of tonal induction systems including signal processing methods and models for tonality induction; </li>
  <li> It defines a set of requirements for low-level tonal features; </li>
  <li> It provides a quantitative evaluation of the proposed methods with respect to similar ones for audio key finding. This quantitative evaluation is divided in different stages, analyzing the influence of each one; </li>
  <li> It supports the idea that some application contexts do not need a accurate symbolic transcription, thus bridging the gap between audio and symbolic-oriented methods without the need of a perfect transcription; </li>
  <li> It extents current literature dealing with classical music to other musical genres; </li>
  <li> It shows the usefulness of tonal descriptors for music similarity; </li>
  <li> It provides an optimized method which is used in a real system for music visualization and retrieval, working with over a million of musical pieces. </li>
</ul>
},
  author = {Emilia G{\'o}mez}
}

@article{miroslaw2006pitchshift,
author = {Hermanowicz, Ewa and Rojewski, Miroslaw},
year = {2006},
month = {12},
pages = {},
title = {Pitch shifter based on complex dynamic representation rescaling and direct digital synthesis},
volume = {54},
journal = {Bulletin of the Polish Academy of Sciences: Technical Sciences}
}

@article{grovedict,
 ISSN = {00274380, 1534150X},
 URL = {http://www.jstor.org/stable/900733},
 author = {Gordon Theil},
 journal = {Notes},
 number = {1},
 pages = {45--48},
 publisher = {Music Library Association},
 reviewed-author = {Barry Kernfeld},
 volume = {59},
 year = {2002}
}

@book{pitchneuralcoding,
title = "Pitch: Neural Coding and Perception",
author = "{Oxenham (ed.)}, {Andrew J.} and Oxenham, {Andrew J}",
editor = "Plack, {C. J.} and Popper, {A. N.} and Fay, {R. R.}",
year = "2005",
language = "English",
publisher = "Springer",
}

@article{stevensloudness,
author = {Stevens,S. S. },
title = {The Measurement of Loudness},
journal = {The Journal of the Acoustical Society of America},
volume = {27},
number = {5},
pages = {815-829},
year = {1955},
doi = {10.1121/1.1908048},

URL = { 
        https://doi.org/10.1121/1.1908048
    
},
eprint = { 
        https://doi.org/10.1121/1.1908048
    
}

}


@Book{ ericksonsoundstructure,
author = { Erickson, Robert },
title = { Sound structure in music },
isbn = { 0520023765 },
publisher = { University of California Press Berkeley },
pages = { ix, 205 p. : },
year = { 1975 },
type = { Book },
language = { English },
subjects = { Music -- Acoustics and physics.; Sound. },
life-dates = { 1975 -  },
catalogue-url = { https://nla.gov.au/nla.cat-vn458283 },
}


@article{ewa2006pitch,
author = {Hermanowicz, Ewa and Rojewski, Miroslaw},
year = {2006},
month = {12},
pages = {},
title = {Pitch shifter based on complex dynamic representation rescaling and direct digital synthesis},
volume = {54},
journal = {Bulletin of the Polish Academy of Sciences: Technical Sciences}
}

@book{benward2003music,
  title={Music in Theory and Practice},
  author={Benward, B. and Saker, M.N.},
  number={v. 1},
  isbn={9780072942620},
  lccn={2001032967},
  series={Music in Theory and Practice},
  url={https://books.google.co.id/books?id=IkYJAQAAMAAJ},
  year={2003},
  publisher={McGraw-Hill}
}

@book{jorgensen1991tuning,
  title={Tuning: containing the perfection of eighteenth-century temperament, the lost art of nineteenth-century temperament, and the science of equal temperament, complete with instructions for aural and electronic tuning},
  author={Jorgensen, O.},
  isbn={9780870132902},
  lccn={lc90050887},
  url={https://books.google.co.id/books?id=AmMJAQAAMAAJ},
  year={1991},
  publisher={Michigan State University Press}
}
@misc{setharestuningtimbre, title={Relating Tuning and Timbre}, url={http://sethares.engr.wisc.edu/consemi.html}, journal={Relating Tuning and Timbre}, author={Sethares, William A.}}

@article{pearson1895note,
  added-at = {2017-11-09T10:56:39.000+0100},
  author = {Pearson, Karl},
  biburl = {https://www.bibsonomy.org/bibtex/25f8cf240981fc543a2192aa475a0f88d/thoni},
  interhash = {aa8d777b055eb149c9e98f9d7a8384c5},
  intrahash = {5f8cf240981fc543a2192aa475a0f88d},
  journal = {Proceedings of the Royal Society of London},
  keywords = {pearson coefficient definition citedby:scholar:count:840 citedby:scholar:timestamp:2017-11-9},
  pages = {240--242},
  publisher = {JSTOR},
  timestamp = {2017-11-09T10:56:39.000+0100},
  title = {Note on regression and inheritance in the case of two parents},
  volume = 58,
  year = 1895
}


@book{Thiemel2001,
  doi = {10.1093/gmo/9781561592630.article.08458},
  url = {https://doi.org/10.1093/gmo/9781561592630.article.08458},
  year = {2001},
  publisher = {Oxford University Press},
  author = {Matthias Thiemel},
  title = {Dynamics}
}

@book{Walpole,
  added-at = {2011-04-12T12:51:01.000+0200},
  address = {Upper Saddle River},
  author = {Walpole, Ronald E. and Myers, Raymond H. and Myers, Sharon L. and Ye, Keying},
  biburl = {https://www.bibsonomy.org/bibtex/219a59df44d8aa5a63e6844e0c066cb21/arnsholt},
  edition = {8th},
  interhash = {e1efaca49b5c9c0d8e89a50bccb98901},
  intrahash = {19a59df44d8aa5a63e6844e0c066cb21},
  keywords = {statistics},
  publisher = {Pearson Education},
  timestamp = {2011-04-29T13:06:24.000+0200},
  title = {Probability \& statistics for engineers and scientists},
  year = 2007
}

@article{oddsratio,
author = {Szumilas, Magdalena},
year = {2010},
month = {08},
pages = {227-9},
title = {Explaining Odds Ratio},
volume = {19},
journal = {Journal of the Canadian Academy of Child and Adolescent Psychiatry = Journal de l'Académie canadienne de psychiatrie de l'enfant et de l'adolescent}
}